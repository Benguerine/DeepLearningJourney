{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20733,"status":"ok","timestamp":1754291699587,"user":{"displayName":"Seifeddine Benguerine","userId":"11606968322762573427"},"user_tz":-60},"id":"bV3l9j6oHkwN","outputId":"a6763658-89fd-46c7-9937-a46edba1f870"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1754291699590,"user":{"displayName":"Seifeddine Benguerine","userId":"11606968322762573427"},"user_tz":-60},"id":"BwN7dCSRI3lk","outputId":"42845153-a8fa-4cd9-8924-05ff38885269"},"outputs":[{"name":"stdout","output_type":"stream","text":["last edit: 2025-08-04 07:14:59.390413\n"]}],"source":["import datetime\n","print(f\"last edit: {datetime.datetime.now()}\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1754291699628,"user":{"displayName":"Seifeddine Benguerine","userId":"11606968322762573427"},"user_tz":-60},"id":"EEQF5wyEJQQu","outputId":"e85e6458-3864-46b9-de67-f9bb1621f81a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Aug  4 07:14:59 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   49C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2425,"status":"ok","timestamp":1754291702078,"user":{"displayName":"Seifeddine Benguerine","userId":"11606968322762573427"},"user_tz":-60},"id":"nFzwtZXqrT9b","outputId":"442a9636-a5a4-41d2-d47c-42fa7dc01c4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2025-08-04 07:14:59--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.99.207, 142.250.107.207, 142.251.188.207, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.99.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 168546183 (161M) [application/zip]\n","Saving to: ‚Äò10_food_classes_10_percent.zip‚Äô\n","\n","10_food_classes_10_ 100%[===================\u003e] 160.74M   183MB/s    in 0.9s    \n","\n","2025-08-04 07:15:00 (183 MB/s) - ‚Äò10_food_classes_10_percent.zip‚Äô saved [168546183/168546183]\n","\n"]}],"source":["# Get data (10% of labels)\n","import zipfile\n","\n","# Download data\n","!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n","\n","# Unzip the downloaded file\n","zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\", \"r\")\n","zip_ref.extractall()\n","zip_ref.close()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1754291702096,"user":{"displayName":"Seifeddine Benguerine","userId":"11606968322762573427"},"user_tz":-60},"id":"DfJh_UPBrwc3","outputId":"bc9788ff-3bc1-4150-e9c3-dd7d98be5600"},"outputs":[{"name":"stdout","output_type":"stream","text":["there are 2 directories and 0 images in '10_food_classes_10_percent\n","there are 10 directories and 0 images in '10_food_classes_10_percent/test\n","there are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi\n","there are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice\n","there are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry\n","there are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings\n","there are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza\n","there are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon\n","there are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen\n","there are 0 directories and 250 images in '10_food_classes_10_percent/test/steak\n","there are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger\n","there are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream\n","there are 10 directories and 0 images in '10_food_classes_10_percent/train\n","there are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi\n","there are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice\n","there are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry\n","there are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings\n","there are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza\n","there are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon\n","there are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen\n","there are 0 directories and 75 images in '10_food_classes_10_percent/train/steak\n","there are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger\n","there are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream\n"]}],"source":["import os\n","\n","for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n","  print(f\"there are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3589,"status":"ok","timestamp":1754291705689,"user":{"displayName":"Seifeddine Benguerine","userId":"11606968322762573427"},"user_tz":-60},"id":"Ap8y4ioitBz0","outputId":"0d1c0668-af87-45cd-a710-6df20d1a5fa3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training images:\n","Found 750 images belonging to 10 classes.\n","Testing images:\n","Found 2500 images belonging to 10 classes.\n"]}],"source":["# Setup data inputs\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","IMAGE_SHAPE = (224, 224)\n","BATCH_SIZE = 32\n","\n","train_dir = \"10_food_classes_10_percent/train/\"\n","test_dir = \"10_food_classes_10_percent/test/\"\n","\n","train_datagen = ImageDataGenerator(rescale=1/255.)\n","test_datagen = ImageDataGenerator(rescale=1/255.)\n","\n","print(\"Training images:\")\n","train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n","                                               target_size=IMAGE_SHAPE,\n","                                               batch_size=BATCH_SIZE,\n","                                               class_mode=\"categorical\")\n","\n","print(\"Testing images:\")\n","test_data = train_datagen.flow_from_directory(test_dir,\n","                                              target_size=IMAGE_SHAPE,\n","                                              batch_size=BATCH_SIZE,\n","                                              class_mode=\"categorical\")"]},{"cell_type":"markdown","metadata":{"id":"5oKN3R4SzRN8"},"source":["##**Setting up callback**"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1754291705694,"user":{"displayName":"Seifeddine Benguerine","userId":"11606968322762573427"},"user_tz":-60},"id":"AjCSyleOvbdH"},"outputs":[],"source":["# Create tensorboard callback (functionized because need to create a new one for each model)\n","import datetime\n","def create_tensorboard_callback(dir_name, experiment_name):\n","  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n","      log_dir=log_dir\n","  )\n","  print(f\"Saving TensorBoard log files to: {log_dir}\")\n","  return tensorboard_callback"]},{"cell_type":"markdown","metadata":{"id":"yxGZpP3s9y8N"},"source":["##**Creating models using tensorflow Hub**"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":999,"status":"ok","timestamp":1754291706711,"user":{"displayName":"Seifeddine Benguerine","userId":"11606968322762573427"},"user_tz":-60},"id":"nttdAlIcAZ99"},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"dkcnzLtcfu-o"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow==2.15.0\n","  Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n","Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.11/dist-packages (0.16.1)\n","Collecting keras==2.15.0\n","  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: absl-py\u003e=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.4.0)\n","Requirement already satisfied: astunparse\u003e=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.6.3)\n","Requirement already satisfied: flatbuffers\u003e=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,\u003e=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.6.0)\n","Requirement already satisfied: google-pasta\u003e=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\n","Requirement already satisfied: h5py\u003e=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.14.0)\n","Requirement already satisfied: libclang\u003e=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (18.1.1)\n","Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0)\n","  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Collecting numpy\u003c2.0.0,\u003e=1.23.5 (from tensorflow==2.15.0)\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.0)\n","Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c5.0.0dev,\u003e=3.20.3 (from tensorflow==2.15.0)\n","  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (75.2.0)\n","Requirement already satisfied: six\u003e=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.17.0)\n","Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.1.0)\n","Requirement already satisfied: typing-extensions\u003e=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.14.1)\n","Collecting wrapt\u003c1.15,\u003e=1.11.0 (from tensorflow==2.15.0)\n","  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem\u003e=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.37.1)\n","Requirement already satisfied: grpcio\u003c2.0,\u003e=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.74.0)\n","Collecting tensorboard\u003c2.16,\u003e=2.15 (from tensorflow==2.15.0)\n","  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n","Collecting tensorflow-estimator\u003c2.16,\u003e=2.15.0 (from tensorflow==2.15.0)\n","  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: tf-keras\u003e=2.14.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub) (2.18.0)\n","Requirement already satisfied: wheel\u003c1.0,\u003e=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse\u003e=1.6.0-\u003etensorflow==2.15.0) (0.45.1)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.16,\u003e=2.15-\u003etensorflow==2.15.0) (2.38.0)\n","Requirement already satisfied: google-auth-oauthlib\u003c2,\u003e=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.16,\u003e=2.15-\u003etensorflow==2.15.0) (1.2.2)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.16,\u003e=2.15-\u003etensorflow==2.15.0) (3.8.2)\n","Requirement already satisfied: requests\u003c3,\u003e=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.16,\u003e=2.15-\u003etensorflow==2.15.0) (2.32.3)\n","Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.16,\u003e=2.15-\u003etensorflow==2.15.0) (0.7.2)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.16,\u003e=2.15-\u003etensorflow==2.15.0) (3.1.3)\n","INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n","Collecting tf-keras\u003e=2.14.1 (from tensorflow-hub)\n","  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n","  Downloading tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n","  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n","  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: cachetools\u003c6.0,\u003e=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow==2.15.0) (5.5.2)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow==2.15.0) (0.4.2)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow==2.15.0) (4.9.1)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib\u003c2,\u003e=0.5-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow==2.15.0) (2.0.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow==2.15.0) (3.4.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow==2.15.0) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow==2.15.0) (2.5.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow==2.15.0) (2025.7.14)\n","Requirement already satisfied: MarkupSafe\u003e=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug\u003e=1.0.1-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow==2.15.0) (3.0.2)\n","Requirement already satisfied: pyasn1\u003c0.7.0,\u003e=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow==2.15.0) (0.6.1)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c2,\u003e=0.5-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow==2.15.0) (3.3.1)\n","Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tf_keras-2.15.1-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, protobuf, numpy, keras, ml-dtypes, tensorboard, tensorflow, tf-keras\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.17.2\n","    Uninstalling wrapt-1.17.2:\n","      Successfully uninstalled wrapt-1.17.2\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 5.29.5\n","    Uninstalling protobuf-5.29.5:\n","      Successfully uninstalled protobuf-5.29.5\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.8.0\n","    Uninstalling keras-3.8.0:\n","      Successfully uninstalled keras-3.8.0\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.4.1\n","    Uninstalling ml-dtypes-0.4.1:\n","      Successfully uninstalled ml-dtypes-0.4.1\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.18.0\n","    Uninstalling tensorboard-2.18.0:\n","      Successfully uninstalled tensorboard-2.18.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.18.0\n","    Uninstalling tensorflow-2.18.0:\n","      Successfully uninstalled tensorflow-2.18.0\n","  Attempting uninstall: tf-keras\n","    Found existing installation: tf_keras 2.18.0\n","    Uninstalling tf_keras-2.18.0:\n","      Successfully uninstalled tf_keras-2.18.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ydf 0.13.0 requires protobuf\u003c7.0.0,\u003e=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n","tensorstore 0.1.74 requires ml_dtypes\u003e=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n","dopamine-rl 4.1.2 requires tf-keras\u003e=2.18.0, but you have tf-keras 2.15.1 which is incompatible.\n","tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n","tensorflow-decision-forests 1.11.0 requires tf-keras~=2.17, but you have tf-keras 2.15.1 which is incompatible.\n","tensorflow-text 2.18.1 requires tensorflow\u003c2.19,\u003e=2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n","grpcio-status 1.71.2 requires protobuf\u003c6.0dev,\u003e=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n","thinc 8.3.6 requires numpy\u003c3.0.0,\u003e=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy\u003c2.3.0,\u003e=2; python_version \u003e= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy\u003c2.3.0,\u003e=2; python_version \u003e= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy\u003c2.3.0,\u003e=2; python_version \u003e= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","jax 0.5.2 requires ml_dtypes\u003e=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.2.0 numpy-1.26.4 protobuf-4.25.8 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tf-keras-2.15.1 wrapt-1.14.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"a4c98c4955134069970d34ff20246339","pip_warning":{"packages":["google","keras","ml_dtypes","numpy","tensorflow","wrapt"]}}},"metadata":{},"output_type":"display_data"}],"source":["pip install tensorflow==2.15.0 tensorflow-hub keras==2.15.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9AoNV8UugYOp"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow version: 2.18.0\n","TensorFlow Hub version: 0.16.1\n"]}],"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","print(f\"TensorFlow version: {tf.__version__}\")\n","print(f\"TensorFlow Hub version: {hub.__version__}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"VCB3N0KB1jaA"},"outputs":[],"source":["## https://www.tensorflow.org/hub\n","## https://www.kaggle.com/models?tfhub-redirect=true\u0026owner-type=organization\u0026datatype=14102\u0026task=16686\n","## https://github.com/paperswithcode"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rJHLiKFX-AQU"},"outputs":[],"source":["# Model URLs\n","resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n","efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n","\n","# Define image shape (most TensorFlow Hub models expect 224x224)\n","IMAGE_SHAPE = (224, 224)"]},{"cell_type":"markdown","metadata":{"id":"faT26j8zq59A"},"source":["These URLs link to a saved pretrained model on TensorFlow Hub.\n","\n","When we use them in our model, the model will automatically be downloaded for us to use.\n","\n","To do this, we can use the [`KerasLayer()`](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer) model inside the TensorFlow hub library.\n","\n","Since we're going to be comparing two models, to save ourselves code, we'll create a function `create_model()`. This function will take a model's TensorFlow Hub URL, instatiate a Keras Sequential model with the appropriate number of output layers and return the model."]},{"cell_type":"markdown","metadata":{"id":"0J0ou_FbkWJq"},"source":["The problem: **`error : Only instances of `keras.Layer` can be added to a Sequential model`** solve by two ways, I'm using way 2.\n","\n","1. Try installing `tf_keras` by running `pip install tf_keras`. Then `import tf_keras` and and use `tf_keras.Sequential` instead of `tf.keras.Sequential` as shown below:\n","\u003e\n","\n","```\n","import tf_keras\n","\n","mobilenet_v2 =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n","classifier_model = mobilenet_v2\n","IMAGE_SHAPE = (224, 224)\n","\n","classifier = tf_keras.Sequential([\n","    hub.KerasLayer(classifier_model, input_shape=IMAGE_SHAPE+(3,))\n","])\n","```\n","\n","2. Recommended:\n","\u003e\n","\n","```\n","pip install tensorflow==2.15.0 tensorflow-hub keras==2.15.0\n","```\n","\n","\n","\u003e üîë: [Full solution](https://stackoverflow.com/questions/78530756/error-only-instances-of-keras-layer-can-be-added-to-a-sequential-model)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"H_HreHNNIJZ0"},"outputs":[],"source":["def create_model(model_url, num_classes=10):\n","  \"\"\"Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n","\n","  Args:\n","    model_url (str): A TensorFlow Hub feature extraction URL.\n","    num_classes (int): Number of output neurons in output layer,\n","      should be equal to number of target classes, default 10.\n","\n","  Returns:\n","    An uncompiled Keras Sequential model with model_url as feature\n","    extractor layer and Dense output layer with num_classes outputs.\n","  \"\"\"\n","  # Download the pretrained model and save it as a Keras layer\n","  feature_extractor_layer = hub.KerasLayer(model_url,\n","                                           trainable=False, # freeze the underlying patterns\n","                                           name='feature_extraction_layer',\n","                                           input_shape=IMAGE_SHAPE+(3,)) # define the input image shape\n","\n","  # Create our own model\n","  model = tf.keras.Sequential([\n","    feature_extractor_layer, # use the feature extraction layer as the base\n","    layers.Dense(num_classes, activation='softmax', name='output_layer') # create our own output layer\n","  ])\n","\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"v_Y4kvH_i0_Z"},"outputs":[{"ename":"ValueError","evalue":"Only instances of `keras.Layer` can be added to a Sequential model. Received: \u003ctensorflow_hub.keras_layer.KerasLayer object at 0x7d16c9fd29d0\u003e (of type \u003cclass 'tensorflow_hub.keras_layer.KerasLayer'\u003e)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3065345535.py\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mresnet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data_10_percent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Compile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m resnet_model.compile(loss='categorical_crossentropy',\n","\u001b[0;32m/tmp/ipython-input-4061328425.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(model_url, num_classes)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;31m# Create our own model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 20\u001b[0;31m   model = tf.keras.Sequential([\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mfeature_extractor_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# use the feature extraction layer as the base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output_layer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# create our own output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, trainable, name)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer, rebuild)\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Only instances of `keras.Layer` can be added to a Sequential model. Received: \u003ctensorflow_hub.keras_layer.KerasLayer object at 0x7d16c9fd29d0\u003e (of type \u003cclass 'tensorflow_hub.keras_layer.KerasLayer'\u003e)"]}],"source":["# Create model\n","resnet_model = create_model(resnet_url, num_classes=train_data_10_percent.num_classes)\n","\n","# Compile\n","resnet_model.compile(loss='categorical_crossentropy',\n","                     optimizer=tf.keras.optimizers.Adam(),\n","                     metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HX0hqpITjE3t"},"outputs":[],"source":["# Fit the model\n","resnet_history = resnet_model.fit(train_data_10_percent,\n","                                  epochs=5,\n","                                  steps_per_epoch=len(train_data_10_percent),\n","                                  validation_data=test_data,\n","                                  validation_steps=len(test_data),\n","                                  # Add TensorBoard callback to model (callbacks parameter takes a list)\n","                                  callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\", # save experiment logs here\n","                                                                         experiment_name=\"resnet50V2\")]) # name of log files"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Xx250HctkK8J"},"outputs":[],"source":["# If you wanted to, you could really turn this into a helper function to load in with a helper.py script...\n","import matplotlib.pyplot as plt\n","\n","# Plot the validation and training data separately\n","def plot_loss_curves(history):\n","  \"\"\"\n","  Returns separate loss curves for training and validation metrics.\n","  \"\"\"\n","  loss = history.history['loss']\n","  val_loss = history.history['val_loss']\n","\n","  accuracy = history.history['accuracy']\n","  val_accuracy = history.history['val_accuracy']\n","\n","  epochs = range(len(history.history['loss']))\n","\n","  # Plot loss\n","  plt.plot(epochs, loss, label='training_loss')\n","  plt.plot(epochs, val_loss, label='val_loss')\n","  plt.title('Loss')\n","  plt.xlabel('Epochs')\n","  plt.legend()\n","\n","  # Plot accuracy\n","  plt.figure()\n","  plt.plot(epochs, accuracy, label='training_accuracy')\n","  plt.plot(epochs, val_accuracy, label='val_accuracy')\n","  plt.title('Accuracy')\n","  plt.xlabel('Epochs')\n","  plt.legend();"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"svFF9i6irkS2"},"outputs":[],"source":["plot_loss_curves(resnet_history)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"43evuNAqrvMR"},"outputs":[],"source":["resnet_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"byzn57QwsXsb"},"outputs":[],"source":["# Create model\n","efficientnet_model = create_model(model_url=efficientnet_url, # use EfficientNetB0 TensorFlow Hub URL\n","                                  num_classes=train_data_10_percent.num_classes)\n","\n","# Compile EfficientNet model\n","efficientnet_model.compile(loss='categorical_crossentropy',\n","                           optimizer=tf.keras.optimizers.Adam(),\n","                           metrics=['accuracy'])\n","\n","# Fit EfficientNet model\n","efficientnet_history = efficientnet_model.fit(train_data_10_percent, # only use 10% of training data\n","                                              epochs=5, # train for 5 epochs\n","                                              steps_per_epoch=len(train_data_10_percent),\n","                                              validation_data=test_data,\n","                                              validation_steps=len(test_data),\n","                                              callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n","                                                                                     # Track logs under different experiment name\n","                                                                                     experiment_name=\"efficientnetB0\")])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6vOaBid2smWZ"},"outputs":[],"source":["plot_loss_curves(efficientnet_history)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zmyRTT1EzYDi"},"outputs":[],"source":["efficientnet_model.summary()"]},{"cell_type":"markdown","metadata":{"id":"c9v6hiKAzw0d"},"source":["##**Comparing the models (Resnet_model \u0026 Efficientnet_model)**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"07p1GQEyzmgs"},"outputs":[],"source":["# Upload TensorBoard dev records\n","!tensorboard dev upload --logdir ./tensorflow_hub/ \\\n","  --name \"EfficientNetB0 vs. ResNet50V2\" \\\n","  --description \"Comparing two different TF Hub feature extraction models architectures using 10% of training images\" \\\n","  --one_shot"]},{"cell_type":"markdown","metadata":{"id":"vteBAYuA8VJY"},"source":["### Listing experiments you've saved to TensorBoard\n","\n","To see all of the experiments you've uploaded you can use the command:\n","\n","```tensorboard dev list```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mN7zilfNxXSZ"},"outputs":[],"source":["!tensorboard dev list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m_ruQafM8ZE1"},"outputs":[],"source":["# Install wandb\n","!pip install wandb\n","\n","# Login to wandb (you'll need to create a free account at wandb.ai)\n","import wandb\n","wandb.login()\n","\n","# Initialize wandb project\n","wandb.init(\n","    project=\"efficientnet-vs-resnet-comparison\",\n","    name=\"EfficientNetB0 vs ResNet50V2\",\n","    notes=\"Comparing two different TF Hub feature extraction models using 10% of training images\"\n",")\n","\n","# Method 1: Import existing TensorBoard logs\n","# First, let's check what's in your tensorboard directory\n","import os\n","print(\"TensorBoard log directories:\")\n","for root, dirs, files in os.walk(\"./tensorflow_hub/\"):\n","    for file in files:\n","        if file.endswith('.tfevents') or 'events.out.tfevents' in file:\n","            print(f\"Found: {os.path.join(root, file)}\")\n","\n","# Import your existing logs - make sure to run this AFTER wandb.init()\n","wandb.init(\n","    project=\"efficientnet-vs-resnet-comparison\",\n","    name=\"imported-tensorboard-logs\"\n",")\n","\n","# Sync TensorBoard logs to wandb\n","try:\n","    wandb.tensorboard.patch(root_logdir=\"./tensorflow_hub/\")\n","    print(\"‚úÖ TensorBoard logs imported successfully!\")\n","except Exception as e:\n","    print(f\"‚ùå Error importing logs: {e}\")\n","    print(\"Make sure your TensorBoard logs exist in ./tensorflow_hub/\")\n","\n","wandb.finish()\n","\n","# Method 2: Quick test with dummy data to verify wandb is working\n","wandb.init(\n","    project=\"efficientnet-vs-resnet-comparison\",\n","    name=\"test-run\"\n",")\n","\n","# Log some test metrics to verify the connection\n","import numpy as np\n","for epoch in range(10):\n","    # Simulate training metrics\n","    acc = 0.5 + 0.3 * (1 - np.exp(-epoch/3)) + np.random.normal(0, 0.02)\n","    loss = 2.0 * np.exp(-epoch/3) + np.random.normal(0, 0.05)\n","\n","    wandb.log({\n","        \"epoch\": epoch,\n","        \"accuracy\": acc,\n","        \"loss\": loss,\n","        \"learning_rate\": 0.001 * (0.9 ** epoch)\n","    })\n","\n","print(\"‚úÖ Test data logged!\")\n","wandb.finish()\n","import tensorflow as tf\n","\n","# Example training loop with wandb logging\n","def train_with_wandb(model, train_dataset, val_dataset, model_name):\n","    # Configure wandb to track this specific model\n","    config = wandb.config\n","    config.model_name = model_name\n","    config.learning_rate = 0.001\n","    config.batch_size = 32\n","    config.epochs = 10\n","\n","    # Compile model\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=config.learning_rate),\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","\n","    # Create wandb callback\n","    wandb_callback = wandb.keras.WandbCallback(\n","        monitor='val_accuracy',\n","        save_model=True,\n","        save_graph=True\n","    )\n","\n","    # Train model\n","    history = model.fit(\n","        train_dataset,\n","        validation_data=val_dataset,\n","        epochs=config.epochs,\n","        callbacks=[wandb_callback]\n","    )\n","\n","    return history\n","\n","# Example usage for both models\n","# For EfficientNetB0\n","wandb.init(\n","    project=\"efficientnet-vs-resnet-comparison\",\n","    name=\"EfficientNetB0-experiment\",\n","    reinit=True\n",")\n","# train_with_wandb(efficientnet_model, train_ds, val_ds, \"EfficientNetB0\")\n","wandb.finish()\n","\n","# For ResNet50V2\n","wandb.init(\n","    project=\"efficientnet-vs-resnet-comparison\",\n","    name=\"ResNet50V2-experiment\",\n","    reinit=True\n",")\n","# train_with_wandb(resnet_model, train_ds, val_ds, \"ResNet50V2\")\n","wandb.finish()\n","\n","# Method 3: Log custom metrics and comparisons\n","wandb.init(\n","    project=\"efficientnet-vs-resnet-comparison\",\n","    name=\"model-comparison-summary\"\n",")\n","\n","# Log comparison metrics\n","wandb.log({\n","    \"EfficientNetB0/final_accuracy\": 0.85,  # Replace with actual values\n","    \"ResNet50V2/final_accuracy\": 0.82,\n","    \"EfficientNetB0/final_loss\": 0.45,\n","    \"ResNet50V2/final_loss\": 0.52,\n","    \"EfficientNetB0/params\": 5288548,  # Model parameters\n","    \"ResNet50V2/params\": 25636712,\n","    \"training_data_percentage\": 10\n","})\n","\n","# Create comparison table\n","comparison_table = wandb.Table(\n","    columns=[\"Model\", \"Accuracy\", \"Loss\", \"Parameters\", \"Training Time\"],\n","    data=[\n","        [\"EfficientNetB0\", 0.85, 0.45, 5288548, \"15 min\"],\n","        [\"ResNet50V2\", 0.82, 0.52, 25636712, \"25 min\"]\n","    ]\n",")\n","wandb.log({\"model_comparison\": comparison_table})\n","\n","# Log model artifacts (optional)\n","# wandb.save(\"efficientnet_model.h5\")\n","# wandb.save(\"resnet_model.h5\")\n","\n","wandb.finish()\n","\n","print(\"‚úÖ Experiments logged to Weights \u0026 Biases!\")\n","print(\"üîó View your dashboard at: https://wandb.ai/\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wv8gWIDv-uEg"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOwNafFF40rdSGLjXsZ2ADc","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}